---
title: "kullar_2023_replication"
author: "Bj√∂rn Siepe"
date: "`r Sys.Date()`"
output: html_document
---
This document repeats the preprocessing and modeling steps by Kullar et al. (2023), as outlined in the corresponding [GitHub Repo](https://github.com/mkullar/DataDrivenEmotionDynamics/blob/main/DataDrivenEmotionDynamics_Code.Rmd)

We omit the confirmatory subgrouping here and modify some of the code in order to suit our purpose. 

```{r kullar-packages}
# packages used
library(dplyr)
library(data.table)
library(imputeTS)
library(pracma)

# GIMME packages
library(gimme)
library(perturbR)

# Further packages 
library(here)

set.seed(35037)
```


# Pre-processing ESM data

```{r}
# Impute data in order to use standardized residuals of time-series data
esmdata <- read.csv(here::here("data/kullar_2023/esmdata.csv")) 

b1var <- esmdata
    shortem <- c("moniker", "time", "Happy_e","Enthusiastic","Pleased", "Relaxed", "Nervous", "Sad", "Irritated", "Angry", "Stressed", "MWoccur", "EmotionChronometry")
    b1var <- b1var[shortem]
    imputevar <- c("Happy_e","Enthusiastic","Pleased", "Relaxed", "Nervous", "Sad", "Irritated", "Angry", "Stressed", "MWoccur", "EmotionChronometry")
    b1var$moniker <- as.factor(b1var$moniker)
#loop through participants
for(i in levels(b1var$moniker)) {
    b1varimp <- b1var[b1var$moniker == i,]
        for(j in imputevar) {
          b1varimp[,j] <- na_ma(b1varimp[,j], k=2, weighting = "simple")
        }
    #save all files in folder for use at individual level
    savefile <- paste0("data/kullar_2023//step1/", i, ".csv", sep = "") #save first preprocessed step here to a folder you name 'step1' (or change the name to what you would like)
    write.csv(b1varimp, file = savefile, row.names = FALSE)
    print(paste("Dataframe Saved:", i))
}
    # Reduce down the most highly correlating emotion variables used in analysis of input variables
    data <- rbindlist(lapply(list.files("data/kullar_2023/step1/", full.names = TRUE), fread), fill = TRUE) #read in individual files from prior step
        data$moniker <- as.factor(data$moniker)
    #reduce down the most highly correlating emotion variables
    data$HighCorrNegative <- (data$Angry + data$Irritated)/2 #referred to as "Angry" in manuscript for ease of interpreting
    data$HighCorrPositive <- (data$Happy_e + data$Pleased)/2 #referred to as "Happy" in manuscript for ease of interpreting
    data <- as.data.frame(data)
    corrred <- c("moniker", "time", "HighCorrPositive", "HighCorrNegative", "Enthusiastic", "Relaxed", "Sad", "Nervous", "Stressed", "MWoccur", "EmotionChronometry")
    data <- data[corrred]

# Remove linear trends in data
scaled.dat <- scale(data[,3:11]) #standardize
names <- data[,1:2]
scaled.dat <- cbind(names, scaled.dat)
data <- scaled.dat

for(i in levels(data$moniker)) {
    data1 <- data[data$moniker == i,]
                data1$Enthusiastic <- detrend(data1$Enthusiastic, tt = 'linear')
                data1$Relaxed <- detrend(data1$Relaxed, tt = 'linear')
                data1$Nervous <- detrend(data1$Nervous, tt = 'linear')
                data1$Sad <- detrend(data1$Sad, tt = 'linear')
                data1$HighCorrPositive <- detrend(data1$HighCorrPositive, tt = 'linear') #Happy, Pleased collapsed
                data1$HighCorrNegative <- detrend(data1$HighCorrNegative, tt = 'linear') #Angry, Irritated collapsed
                data1$Stressed <- detrend(data1$Stressed, tt = 'linear')
                data1$MWoccur <- detrend(data1$MWoccur, tt = 'linear')
                data1$EmotionChronometry <- detrend(data1$EmotionChronometry, tt = 'linear')
    savefile <- paste0("data/kullar_2023/step2/", i, ".csv", sep = "") #save next preprocessed step here to a folder you name 'step2' (or change the name to what you would like)
    write.csv(data1, file = savefile, row.names = FALSE)
    print(paste("Dataframe Saved:", i))
}

# Make sure timing is equally spaced, provide the overnight NA value for overnight spacing of self-report and diurnal time, or exogneous time variable taken as square root of time of day.
datadetrend <- rbindlist(lapply(list.files("data/kullar_2023/step2/", full.names = TRUE), fread), fill = TRUE) #read in individual files from prior step
datadetrend$moniker <- as.factor(datadetrend$moniker)
diurnaltime <- read.csv("data/kullar_2023/overnightanddiurnaltime.csv") #time=ESM timepoint, contime=the continuous order of timepoint occurrence for ordering, raw time=timepoint by hours in the day, TimeofDay=diurnal time calculated by square root of time based on literature.
diurnaltime <- diurnaltime[,-3]
for(i in levels(datadetrend$moniker)) {
    datad1 <- datadetrend[datadetrend$moniker == i,]
          datad1 <- merge(diurnaltime, datad1, by = "time", all = TRUE)
          datad1$moniker[is.na(datad1$moniker)] <- datad1$moniker[1]
          datad1 <- datad1[order(datad1$contime),]
          
          # TODO THIS CODE WAS WRONG! CHANGED 3 to 4, or TimeOfDay gets removed
          remove <- c(1,2,4) #remove original time, continuous time, and moniker in order to feed into GIMME
          datad1 <- datad1[, -(remove)]
    savefile <- paste0 ("data/kullar_2023/finaloutput/", i, ".csv", sep = "") #save final preprocessed step here to a folder you name 'finaloutput' (or change the name to what you would like)
    write.csv(datad1, file = savefile, row.names = FALSE)
    print(paste("Dataframe Saved:", i))
}
## Pre-processing Complete
```

# Data-driven groups GIMME analysis
```{r}
##################################
##     S-GIMME, DATA-DRIVEN     ##
##################################

sgimmefit <- gimme(data = "data/kullar_2023/finaloutput", #folder with individual pre-processed data files named by ID
         out = "data/kullar_2023/gimme_output", #folder to save output
         sep = ",",
         header = TRUE,
         ar = TRUE,
         plot = TRUE,
         subgroup = TRUE,
         paths = NULL, 
         exogenous = "TimeofDay",
         groupcutoff = .75, 
         subcutoff   = .51) 

saveRDS(sgimmefit, file = "data/kullar_2023/kullar_2023_fit.RDS")
sgimmefit <- readRDS("data/kullar_2023/kullar_2023_fit.RDS")



```




# Summarize GIMME
Obtain some individual level summaries: 
```{r summarize-gimme}
# Indicator for temporal and contemporaneous network
n_vars <- sgimmefit$n_vars_total
temp_ind <- 1:(n_vars/2)
cont_ind <- ((n_vars/2)+1) : n_vars

# Check path summary
sgimmefit$path_counts[,temp_ind]
sgimmefit$path_counts[,cont_ind]

# centrality
cent_values <- lapply(sgimmefit$path_est_mats, function(x){
  if(is.double(x)){
    colSums(abs(x))}
  })

max_temp <- list()
max_cont <- list()
for(i in seq_along(cent_values)){
  max_temp[[i]] <- names(which.max(cent_values[[i]][temp_ind]))
  max_cont[[i]] <- names(which.max(cent_values[[i]][cont_ind]))
}

table(unlist(max_temp))
table(unlist(max_cont))

```



